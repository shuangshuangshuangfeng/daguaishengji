## 分词-最大匹配

### NLP项目的流程

- 原始文本 raw data
- 分词 segmentation
- 清洗 cleaning
- 标准化 normalization
- 特征提取 feature extraction
- 建模 modeling
- 评估 

### 分词的工具
- Jieba 
- Snow NlP
- LTP
- HanNLP

### 分词算法-最大匹配算法

最大匹配需要设置一个``max_len``, 就设``max_len = 5``。


最大匹配算法有两种，分别是：
- 前向最大匹配算法
- 后向最大匹配算法


**例子:** 我们经常有意见分歧<br>
**词典:** ["我们"， “经常”， “有”， “意见”, "有意见", "分歧"]<br>

#### 前向最大匹配  forward max matching
从前往后遍历-----><br>
**步骤如下:**<br>
1. （ 以下步骤为从上往下执行）
- [我们经常有]意见分歧  -->词典中**没有**“我们经常有”
- [我们经常]有意见分歧  -->词典中**没有**“我们经常”
- [我们经]常有意见分歧  -->词典中**没有**“我们经”
- [我们]经常有意见分歧  -->词典中**有**“我们”   √ 进入第二步


2. 
 - 我们[经常有意见]分歧  -->词典中**没有**“经常有意见”
 - 我们[经常有意]见分歧  -->词典中**没有**“经常有意”
 - 我们[经常有]意见分歧  -->词典中**没有**“经常有”
 - 我们[经常]有意见分歧  -->词典中**有**“经常”  √ 进入第三步

3. 
 - 我们经常[有意见分歧]  -->词典中**没有**“有意见分歧”
 - 我们经常[有意见分]歧  -->词典中**没有**“有意见分”
 - 我们经常[有意见]  -->词典中**有**“有意见”   √ 进入第四步

4. 
 - 我们经常有意见[分歧]  -->词典中**有**“分歧”   √ 结束

 **结果:** 我们/经常/有意见/分歧

#### 后向最大匹配 backward max matching
从后往前遍历<-----<br>
**步骤如下:**<br>
1. （ 以下步骤为从上往下执行）
- 我们经常[有意见分歧]  -->词典中**没有**“有意见分歧”
- 我们经常有[意见分歧]  -->词典中**没有**“意见分歧”
- 我们经常有意[见分歧]  -->词典中**没有**“见分歧”
- 我们经常有意见[分歧]  -->词典中**有**“分歧”   √ 进入第二步

2. 
- 我们[经常有意见]分歧  -->词典中**没有**“经常有意见”
- 我们经[常有意见]分歧  -->词典中**没有**“常有意见”
- 我们经常[有意见]分歧  -->词典中**有**“有意见”   √ 进入第三步

3. 
- [我们经常]有意见分歧  -->词典中**没有**“我们经常”
- 我[们经常]有意见分歧  -->词典中**没有**“们经常”
- 我们[经常]有意见分歧  -->词典中**有**“经常”  √ 进入第四步

4. 
- [我们]经常有意见分歧  -->词典中**有**“我们”   √ 结束

 **结果:** 我们/经常/有意见/分歧

### 最大匹配的缺点
上面两个算法的结果虽然是一样的，但是针对不同的例子，使用不同的分词算法其结果可能不一样。两种算法同属于最大匹配算法，他们的缺点是:
- 不能细分(可以分的更好，比如上面例子中的"有意见"，可以被分为"有/意见")
- 只能找到局部最优
- 效率低(要一直遍历完)
- 歧义(意思是不能结合语义进行分词，只考虑每个单词，而不是句子的意思)





